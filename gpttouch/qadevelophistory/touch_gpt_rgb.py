import base64
import os
from openai import OpenAI

# âœ… æ›¿æ¢ä¸ºä½ çš„ OpenAI API Key
client = OpenAI(api_key="sk-proj-")  # æ¨èä»ç¯å¢ƒå˜é‡è¯»å–

def encode_image_to_base64(image_path: str) -> str:
    """å°†æœ¬åœ°å›¾ç‰‡ç¼–ç ä¸º base64 å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def build_multimodal_prompt(image_path: str, user_text: str) -> list:
    """æ„å»ºåŒ…å«å›¾ç‰‡å’Œæ–‡å­—çš„ç”¨æˆ·æ¶ˆæ¯"""
    base64_image = encode_image_to_base64(image_path)
    return [
        {"type": "text", "text": user_text},
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}",
                "detail": "low"  # å¯è®¾ä¸º "low" ä»¥é™ä½ token æ¶ˆè€—
            }
        }
    ]

def ask_gpt4_with_image(image_path: str, question: str):
    """è°ƒç”¨ GPT-4o è§†è§‰æ¨¡å‹è¿›è¡Œå›¾ç‰‡ç†è§£"""
    messages = [
        {"role": "system", "content": "You are a tactile assistant that describes GelSight images."},
        {"role": "user", "content": build_multimodal_prompt(image_path, question)}
    ]

    response = client.chat.completions.create(
        model="gpt-4o",  # æˆ– "gpt-4-vision-preview"
        messages=messages,
        max_tokens=256,
        temperature=0.7,
    )

    print("ğŸ¤– Assistant response:\n")
    print(response.choices[0].message.content)

if __name__ == "__main__":
    # âœ… æ›¿æ¢ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„
    image_path = "../data/ssvtp/images_rgb/image_123_rgb.jpg"
    question = "è¯·æ ¹æ®è¿™å¼ å›¾åƒæè¿°ç‰©ä½“è¡¨é¢çº¹ç†ä¸ç¡¬åº¦ã€‚"

    ask_gpt4_with_image(image_path, question)
